---
layout: post
title: "Lecture 9: Approximation algorithms"
description: ""
category: 
tags: []
---
{% include JB/setup %}

<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<a href="https://github.com/emchristiansen/CSE202/tree/gh-pages/_posts">
  <img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub">
</a>

<!--EDIT BELOW THIS LINE, UNLESS YOU ARE DOING SOMETHING SPECIAL.-->

Approximation algorithms

  * Change method -> bound "opportunity cost"
  * Achieve a bound -> Achieve a combination of bounds

# Parallel job scheduling
\\( J\_i = (p\_i, d\_i), 1 \leq p\_i \leq p, 0 < d\_i \\).
P: number of processors available.
Assign each \\( J\_i \\) a time interval \\( s\_i, s\_i + d\_i), s\_i \geq 0 \\).
At any time, total processor use must be \\( \leq P \\).
Objective: Minimize makespan = max finish time.
This looks like a packing problem.

##Approximate algorithm
Order the jobs from largest to smallest \\( p\_i \\).
Add the jobs to the schedule in that order.
If there are enough processors starting at the same time as the last scheduled job, make it start at the same time as the last scheduled job.
Otherwise make it start when the last scheduled job finishes.

Some lower bounds for the above solution:

  * LB1: \\( \max d\_i \\)
  * LB2: Let \\( w := \sum p\_i d\_i \\). Then a bound is \\( \frac{w}{p} \\).

Look at time last job is scheduled.
This the part of the schedule that begins at this point is at most length LB1.
Look at the schedule before this time, and call this range of time T.
At any point, at most \\( \frac{P}{2} \\) can be idle, because otherwise a job would have been scheduled in the idle block.
This holds because of the ordering on \\( p\_i \\). 
So, the work done in time 0 to T is at least \\( \frac{P}{2}T \\), which is a lower bound on W.
So \\( T \leq 2 W / P = 2 * LB2 \\).

So our solution's objective is \\( \leq 2 * LB2 + LB1 \leq 3 * OPT \\).

#Interval scheduling problem
Have set of intervals \\( (s\_i, f\_i) \\).
Have \\( m \\) rooms.
May not have intersecting events.
Objective: Maximize total lengths of scheduled events.
\\[
\sum\_{i \text{ s.t. event } i \text{ is scheduled}}  (f\_i - s\_i)
\\]

##Approximation algorithm
Sort events from longest to shortest duration.
Put each even in first room it fits in.

Make a replacement argument.
As our solution overwrites the optimal solution, in each overwrite of length D it adds D utility and removes at most \\( 3D \\) utility.
This is because the interval we're adding is the current longest.

Lemma: Let \\( I\_1, ..., I\_k \\) be the intervals scheduled by the greedy algorithms, in that order.
Let \\( D\_j \\) be the length of \\( I\_j \\).
Then there is a schedule \\( S\_j \\) such that
\\[
total(S\_j) \geq OPT - 2 \sum\_{j'}^j D\_j.
\\]
Proof by induction.

Theorem: The total duration of the greedy algorithm is \\( \geq \frac{1}{3} OPT \\).
Proof: Apply the lemma with \\( j = k \\).
TotalDuration(GA) >= OPT - 2 * TotalDuration(GA).
So TotalDuration(GA) >= OPT / 3.

Idea of the above approach: In each action, we have an immediate benefit, and an opportunity cost which is bounded in terms of this benefit.
